{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b0c91b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Model  Sensitivity  Specificity  \\\n",
      "0                          Presence of DR - DR_GPT4     0.819672     0.792453   \n",
      "1                     Presence of DR - DR_Gemini1.5     0.983607     0.094340   \n",
      "2                       Presence of DR - DR_Claude3     0.983607     0.094340   \n",
      "3                     Presence of DR - DR_mistralAI     1.000000     0.000000   \n",
      "4               Presence of referable DR - rDR_GPT4     0.800000     0.804688   \n",
      "5             Presence of referable DR - rDR_Gemini     0.680000     0.906250   \n",
      "6             Presence of referable DR - rDR_Clade3     0.960000     0.156250   \n",
      "7            Presence of referable DR - rDR_Mistral     0.620000     0.390625   \n",
      "8        Presence of Maculopathy - Maculopathy_GPT4     0.425000     0.864865   \n",
      "9   Presence of Maculopathy - Maculopathy_Gemini1.5     0.825000     0.229730   \n",
      "10    Presence of Maculopathy - Maculopathy_Claude3     0.100000     0.905405   \n",
      "11  Presence of Maculopathy - Maculopathy_mistralAI     0.400000     0.581081   \n",
      "\n",
      "         PPV       NPV  Accuracy  F1 Score     AUROC  \n",
      "0   0.819672  0.792453  0.807018  0.819672  0.806062  \n",
      "1   0.555556  0.833333  0.570175  0.710059  0.538973  \n",
      "2   0.555556  0.833333  0.570175  0.710059  0.538973  \n",
      "3   0.535088       NaN  0.535088  0.697143  0.500000  \n",
      "4   0.761905  0.837398  0.802632  0.780488  0.802344  \n",
      "5   0.850000  0.783784  0.807018  0.755556  0.793125  \n",
      "6   0.470588  0.833333  0.508772  0.631579  0.558125  \n",
      "7   0.442857  0.568182  0.491228  0.516667  0.505313  \n",
      "8   0.629630  0.735632  0.710526  0.507463  0.644932  \n",
      "9   0.366667  0.708333  0.438596  0.507692  0.527365  \n",
      "10  0.363636  0.650485  0.622807  0.156863  0.502703  \n",
      "11  0.340426  0.641791  0.517544  0.367816  0.490541  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_188\\517466223.py:14: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  npv = tn / (tn + fn)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, roc_auc_score, precision_score, recall_score\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'E:/1 PROJECT/RESEARCH PROJECTS/HTAN research/DR/DAta/wrkingSPSS_editGPT4_2.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Function to calculate the performance metrics\n",
    "def calculate_metrics(true_labels, predictions):\n",
    "    tn, fp, fn, tp = confusion_matrix(true_labels, predictions).ravel()\n",
    "    sensitivity = tp / (tp + fn)  # Recall\n",
    "    specificity = tn / (tn + fp)\n",
    "    ppv = tp / (tp + fp)  # Precision\n",
    "    npv = tn / (tn + fn)\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    f1 = f1_score(true_labels, predictions)\n",
    "    auc = roc_auc_score(true_labels, predictions)\n",
    "    return sensitivity, specificity, ppv, npv, accuracy, f1, auc\n",
    "\n",
    "# Ensure all labels are of the same type\n",
    "def convert_to_int(series):\n",
    "    return series.astype(int)\n",
    "\n",
    "# Convert true labels and predictions to integers\n",
    "df['TRUE_DR'] = convert_to_int(df['TRUE_DR'])\n",
    "df['rDR_true'] = convert_to_int(df['rDR_true'])\n",
    "df['TRUE_Maculopathy'] = convert_to_int(df['TRUE_Maculopathy'])\n",
    "\n",
    "for col in ['DR_GPT4', 'DR_Gemini1.5', 'DR_Claude3', 'DR_mistralAI',\n",
    "            'rDR_GPT4', 'rDR_Gemini', 'rDR_Clade3', 'rDR_Mistral',\n",
    "            'Maculopathy_GPT4', 'Maculopathy_Gemini1.5', 'Maculopathy_Claude3', 'Maculopathy_mistralAI']:\n",
    "    df[col] = convert_to_int(df[col])\n",
    "\n",
    "# Columns for presence of DR\n",
    "true_dr = 'TRUE_DR'\n",
    "predictions_dr = ['DR_GPT4', 'DR_Gemini1.5', 'DR_Claude3', 'DR_mistralAI']\n",
    "\n",
    "# Columns for presence of referable DR\n",
    "true_rdr = 'rDR_true'\n",
    "predictions_rdr = ['rDR_GPT4', 'rDR_Gemini', 'rDR_Clade3', 'rDR_Mistral']\n",
    "\n",
    "# Columns for presence of maculopathy\n",
    "true_maculopathy = 'TRUE_Maculopathy'\n",
    "predictions_maculopathy = ['Maculopathy_GPT4', 'Maculopathy_Gemini1.5', 'Maculopathy_Claude3', 'Maculopathy_mistralAI']\n",
    "\n",
    "# Calculate and print metrics for each model\n",
    "metrics_columns = ['Model', 'Sensitivity', 'Specificity', 'PPV', 'NPV', 'Accuracy', 'F1 Score', 'AUROC']\n",
    "results = []\n",
    "\n",
    "for model in predictions_dr:\n",
    "    metrics = calculate_metrics(df[true_dr], df[model])\n",
    "    results.append(['Presence of DR - ' + model] + list(metrics))\n",
    "\n",
    "for model in predictions_rdr:\n",
    "    metrics = calculate_metrics(df[true_rdr], df[model])\n",
    "    results.append(['Presence of referable DR - ' + model] + list(metrics))\n",
    "\n",
    "for model in predictions_maculopathy:\n",
    "    metrics = calculate_metrics(df[true_maculopathy], df[model])\n",
    "    results.append(['Presence of Maculopathy - ' + model] + list(metrics))\n",
    "\n",
    "# Convert results to a DataFrame for better visualization\n",
    "results_df = pd.DataFrame(results, columns=metrics_columns)\n",
    "\n",
    "# Display the results\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfb3ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
